---
title: "Step 1 BAI_SONA W1"
author: "Hayleigh Armstrong"
date: "Last compiled on `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
---

This script will process the data from the SONA W1 - Beck Anxiety Inventory.

## Preliminary Steps

Load packages:

```{r, warning = FALSE, message = FALSE, include = FALSE}
library(dplyr)
library(tidyverse)
library(Hmisc)
library(psych)
library(ggplot2)
library(ggcorrplot)
library(reshape2)
```

Read in the data:
```{r}
# Hayleigh's Mac: 
df <- read.csv("/Volumes/Emotion Dynamics Lab/PEARS/Data/SEEDS/PEARS_SEEDS_Demographics___Daily_Surveys_SONA_W1/SEEDS SONA W1 Demographics ExpiWell Data Cleaned.csv", na.strings=c("","NA"))

view(df)
```

Subset the data to just the items from the Beck Anxiety Inventory Scale and remove rows that have question headers:
```{r}
df_scale <- select(df [-c(1,2,3,4),], X.7, X.70:X.90)
View(df_scale)
```

Rename the items:
```{r}
colnames(df_scale)[colnames(df_scale)=="X.7"] <- "id"
colnames(df_scale)[colnames(df_scale)=="X.70"] <- "bai_1"
colnames(df_scale)[colnames(df_scale)=="X.71"] <- "bai_2"
colnames(df_scale)[colnames(df_scale)=="X.72"] <- "bai_3"
colnames(df_scale)[colnames(df_scale)=="X.73"] <- "bai_4"
colnames(df_scale)[colnames(df_scale)=="X.74"] <- "bai_5"
colnames(df_scale)[colnames(df_scale)=="X.75"] <- "bai_6"
colnames(df_scale)[colnames(df_scale)=="X.76"] <- "bai_7"
colnames(df_scale)[colnames(df_scale)=="X.77"] <- "bai_8"
colnames(df_scale)[colnames(df_scale)=="X.78"] <- "bai_9"
colnames(df_scale)[colnames(df_scale)=="X.79"] <- "bai_10"
colnames(df_scale)[colnames(df_scale)=="X.80"] <- "bai_11"
colnames(df_scale)[colnames(df_scale)=="X.81"] <- "bai_12"
colnames(df_scale)[colnames(df_scale)=="X.82"] <- "bai_13"
colnames(df_scale)[colnames(df_scale)=="X.83"] <- "bai_14"
colnames(df_scale)[colnames(df_scale)=="X.84"] <- "bai_15"
colnames(df_scale)[colnames(df_scale)=="X.85"] <- "bai_16"
colnames(df_scale)[colnames(df_scale)=="X.86"] <- "bai_17"
colnames(df_scale)[colnames(df_scale)=="X.87"] <- "bai_18"
colnames(df_scale)[colnames(df_scale)=="X.88"] <- "bai_19"
colnames(df_scale)[colnames(df_scale)=="X.89"] <- "bai_20"
colnames(df_scale)[colnames(df_scale)=="X.90"] <- "bai_21"
```

Convert the "prefer not to respond" option to "NA":
```{r}
df_scale[df_scale == 4] <- NA

```

Variables are pulled in as factors and we want to make them numeric values: 
```{r}
df_scale[,paste0("bai_",1:21)] <- lapply(df_scale[,paste0("bai_",1:21)], as.numeric)
str(df_scale)
```

## Investigating missing data
```{r}
missing_summary <- df_scale %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(),
               names_to = "variable",
               values_to = "n_missing") %>%
  mutate(pct_missing = round((n_missing / nrow(df_scale)) * 100, 2)) %>%
  filter(n_missing > 0) %>%
  arrange(desc(pct_missing))

missing_summary
```

## Calculate the scale

### Calculate the standard mean and sum

Sum and mean scores of Beck Anxiety Inventory Scale: 
```{r}

df_scale$bai_sum <- apply(df_scale[,paste0("bai_",1:21)], 1, sum)
df_scale$bai_mean <- apply(df_scale[,paste0("bai_",1:21)], 1, mean)
df_scale$bai_mean <- round(df_scale$bai_mean, digits = 2)

```

Label the items:
```{r}
label(df_scale[["bai_1"]]) <- "Numbness and tingling"
label(df_scale[["bai_2"]]) <- "Feeling hot"
label(df_scale[["bai_3"]]) <- "Wobbliness in legs"
label(df_scale[["bai_4"]]) <- "Unable to relax"
label(df_scale[["bai_5"]]) <- "Fear of worst happening"
label(df_scale[["bai_6"]]) <- "Dizzy or lightheaded"
label(df_scale[["bai_7"]]) <- "Heart pounding or racing"
label(df_scale[["bai_8"]]) <- "Unsteady"
label(df_scale[["bai_9"]]) <- "Terrified"
label(df_scale[["bai_10"]]) <- "Nervous"
label(df_scale[["bai_11"]]) <- "Feelings of choking"
label(df_scale[["bai_12"]]) <- "Hands trembling"
label(df_scale[["bai_13"]]) <- "Shaky"
label(df_scale[["bai_14"]]) <- "Fear of losing control"
label(df_scale[["bai_15"]]) <- "Difficulty breathing"
label(df_scale[["bai_16"]]) <- "Fear of dying"
label(df_scale[["bai_17"]]) <- "Scared"
label(df_scale[["bai_18"]]) <- "Abdominal discomfort"
label(df_scale[["bai_19"]]) <- "Faint"
label(df_scale[["bai_20"]]) <- "Face flushed"
label(df_scale[["bai_21"]]) <- "Sweating (not due to heat)"

label(df_scale[["bai_sum"]]) <- "sum of bai items"
label(df_scale[["bai_mean"]]) <- "mean of bai items"

# Look at the data
head(df_scale)
```

Impute missing values for participants who responded to at least 50% of the items (11 items).

First, pull out columns we do not want used in the mean imputation:
```{r}
# Pull out the id column:
df_scale.na <- df_scale
id.list <- df_scale.na$id

#Remove columns we don't want to include in the mean imputation:
df_scale.na <- subset(df_scale.na, select = -c(id, bai_sum, bai_mean))
```

Impute the means, using the approach for imputing row means described [here](https://statisticsglobe.com/mean-imputation-for-missing-data/):
```{r}
# Count the number of non-missing items per participant
num_items <- ncol(df_scale.na)
min_items_needed <- ceiling(num_items * 0.5)  # at least 50% answered

# Impute row means only for participants who answered >= 50% of items
for(i in 1:nrow(df_scale.na)) {
  non_missing_count <- sum(!is.na(df_scale.na[i, ]))
  
if(non_missing_count >= min_items_needed) {
    # Impute missing values with row mean
    df_scale.na[i, ][is.na(df_scale.na[i, ])] <- mean(as.numeric(df_scale.na[i, ]), na.rm = TRUE)
  } else {
    # If less than 50% answered, set all values to NA
    df_scale.na[i, ] <- NA
  }
}

```

Round the values back to whole numbers:
```{r}
df_scale.na <- round(df_scale.na, digits=0)
```

Calculate the sum and mean, using the suffix _MI to indicate that these columns have had means imputed:
```{r}
df_scale.na$bai_sum_MI <- apply(df_scale.na[,paste0("bai_",1:21)], 1, sum)
df_scale.na$bai_mean_MI <- apply(df_scale.na[,paste0("bai_",1:21)], 1, mean)

```

Put the IDs back into the data frame:
```{r}
df_scale.na$id <- id.list

```

Now we need to merge the imputed cases back into the main data frame. We don't want to end up with duplicate rows of data for the cases that had missing values, so first we will remove these cases from the original data frame:
```{r}
df_scale2 <- df_scale[ ! df_scale$id %in% id.list, ]

```

Now add the newly-imputed cases back into the main data frame:
```{r}
# Create columns in df_scale that we will merge the mean-imputed data into
df_scale2$bai_sum_MI <-df_scale2$bai_sum
df_scale2$bai_mean_MI <-df_scale2$bai_mean

# Create empty columns in df_scale.na for the conventional mean and sum (not MI)
df_scale.na$bai_sum <-NA
df_scale.na$bai_mean <-NA

# Order the columns to be consistent for merge
col_order <- c("id", "bai_1", "bai_2", "bai_3", "bai_4", "bai_5", "bai_6", "bai_7", "bai_8", "bai_9", "bai_10","bai_11","bai_12", "bai_13","bai_14","bai_15", "bai_16", "bai_17", "bai_18", "bai_19","bai_20","bai_21", "bai_sum", "bai_mean", "bai_sum_MI",  "bai_mean_MI")

df_scale2 <- df_scale2[, col_order]
df_scale.na <- df_scale.na[, col_order]

# Merge the imputed cases back into df_scale
df_scale3 <- rbind(df_scale2, df_scale.na)

# Bring in the non-imputed mean and sum from df_scale
df_scale3 <- merge(df_scale3,
                   df_scale[, c("id", "bai_sum", "bai_mean")],
                   by = "id",
                   all.x = TRUE,
                   suffixes = c("", "_orig"))

# Reorder columns
df_scale3 <- df_scale3[, c("id", paste0("bai_", 1:21),
                           "bai_sum_orig", "bai_mean_orig",   # non-imputed
                           "bai_sum_MI", "bai_mean_MI")]      # imputed
```


Save the data file:
```{r, eval = FALSE}
# Hayleigh's Mac:
write.csv(df_scale,'/Volumes/Emotion Dynamics Lab/PEARS/Data/SEEDS/PEARS_SEEDS_Demographics___Daily_Surveys_SONA_W1/Beck Anxiety Inventory-Step1_SONA_W1.csv')

# Jess's Mac:
#write.csv(df_scale,'/Volumes/Emotion Dynamics Lab/PEARS/Data/SEEDS/PEARS_SEEDS_Demographics___Daily_Surveys_SONA_W1/Beck Anxiety Inventory-Step1_SONA_W1.csv')
```

## Examine the Data

### Reliability
```{r, warning = FALSE}
items <- c ("bai_1",  "bai_2" , "bai_3" , "bai_4" , "bai_5" , "bai_6" , "bai_7" , "bai_8" , "bai_9",  "bai_10" , "bai_11" , "bai_12" , "bai_13" , "bai_14" , "bai_15" , "bai_16" , "bai_17",  "bai_18" , "bai_19" , "bai_20" , "bai_21")
alpha(df_scale3[,items])
```

### Descriptive statistics
```{r}
describe(df_scale3$bai_sum_MI)
describe(df_scale3$bai_mean_MI)
```

### Histogram
```{r, warning = FALSE, message = FALSE}
qplot(df_scale3$bai_sum_MI, geom="histogram") 
qplot(df_scale3$bai_mean_MI, geom="histogram") 
```